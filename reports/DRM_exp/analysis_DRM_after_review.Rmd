---
title: "Analysis after review"
author: "Filip Dechterenko"
date: '`r format(Sys.time(), "%d %B, %Y")`'
output: html_document
---

# Load libraries

```{r libraries and preparation}
set.seed(190425)
library(tidyverse); theme_set(theme_classic(16))
library(lme4)
library(here)

source(here("R","utils.R"))
```

# Analysis of protocols

```{r}
prot_dir <- here("data/exp_DRM1/protocols/")
fs <- list.files(prot_dir, full.names = T, pattern = "*.csv") %>% str_subset("P000", negate = T)

df_protocols <- fs %>%
  map(~ read_csv(.)) %>% 
  reduce(rbind)

df_protocols$dist_to_target_image <- NA
ix0 <- df_protocols$query == 0 & df_protocols$type == "target"
for (i in 1:nrow(df_protocols)) {
  curr_prot <- df_protocols$prot_id[i]
  curr_grp  <- df_protocols$grp_order[i]
  
  if(df_protocols$type[i] == "target" & df_protocols$query[i] == 1) {
    ix <- ix0 & df_protocols$prot_id == curr_prot & df_protocols$grp_order == curr_grp & df_protocols$img_name == df_protocols$img_name[i]
    stopifnot(sum(ix) == 1)
    df_protocols$dist_to_target_image[i] <-  df_protocols$trial_id[i]-df_protocols$trial_id[ix]
  }
  
  
}

df_prot_cat <- df_protocols %>% select(prot_id, grp_order,category) %>% distinct()

df_prot_cat2 <- df_prot_cat %>% left_join(df_prot_cat, by = "prot_id") %>% filter(category.x == category.y, grp_order.x!=grp_order.y) %>% 
  filter(grp_order.x < grp_order.y)%>% mutate(dist = grp_order.y-grp_order.x)

df_prot_cat2  %>% summarize(m = mean(dist), sd = sd(dist))
df_prot_cat2 %>% ggplot(aes(x = dist)) + geom_histogram()


# df_resp <- df %>% 
#   select(-X31) %>% 
#   filter(query == 1) %>% 
#   select(subject_id = participant, prot_id:corrKey,key_resp = key_resp_4.keys, correct = key_resp_4.corr, rt_key = key_resp_4.rt,
#          confidence = rating.response, confidence.rt = rating.rt, date) %>% 
#   mutate(corrKey = recode(corrKey, left = "old", right = "new"),
#          key_resp = recode(key_resp, left = "old", right = "new")) %>% 
#   filter(!is.na(correct))
#   
# saveRDS(df_resp, file = here("data/exp_DRM1/results_200219.rds"))



```

# Load data

Data were preprocesseb by scripts 

```{r load data, warning=FALSE, message=FALSE}

df <- readRDS(here("data", "exp_DRM1", "results_after_review_200402.rds"))

df_participants <- readxl::read_excel(here::here("data","exp_DRM1","participants_190509.xlsx"))

plots_dir <- here("plots", "exp_DRM1")

if(!dir.exists(plots_dir)) { dir.create(plots_dir) }

df <- df %>% left_join(df_participants, by = c("subject_id"))



df2 <- df %>% pivot_longer(cols = starts_with("dist_to_tgts"), names_to = "layer", values_to = "distance_to_targets")
df2_dist_tgt <- df %>% pivot_longer(cols = starts_with("avg_dist_between_tgts"), names_to = "layer", values_to = "avg_dist_between_tgts")

df2 <- df2 %>% left_join(df2_dist_tgt %>% select(subject_id,trial_id), by = c("subject_id", "trial_id"))

df2_tgt <- df2 %>% 
  rowwise() %>% 
  mutate(mean_tgt_dist = unlist(distance_to_targets) %>% mean(),
         min_tgt_dist = unlist(distance_to_targets) %>% min(),
         min_tgt_dist_no0 = unlist(distance_to_targets) %>% Filter(gt0,.) %>% min()) %>% 
  distinct()

```



## Means and SD for confidence

```{r}
Mode <- function(x) {
  ux <- unique(x)
  ux[which.max(tabulate(match(x, ux)))]
}
df %>% 
  mutate(confidence_n = factor(confidence, levels = c("not at all sure","somewhat sure","very sure"))) %>% 
  group_by(type) %>% 
  summarise(modus = Mode(confidence),
            mean = mean(as.numeric(confidence_n)),
            sd = sd(as.numeric(confidence_n)),
            median = median(as.numeric(confidence_n)))
```

## Correlation of accuracy with distance to target presentation

```{r}
df_dist_target_images <- 
df %>% left_join(df_protocols %>% 
  select(prot_id, trial_id, grp_order,dist_to_target_image), by = c("prot_id", "trial_id", "grp_order")) 

df_dist_target_images %>% filter(type == "target", query == 1) %>% 
  summarize(m = mean(dist_to_target_image), sd = sd(dist_to_target_image))


p <- df_dist_target_images %>% 
  ggplot(aes(x = dist_to_target_image, y = correct)) + stat_summary(fun.data = "mean_cl_boot") + 
  theme(aspect.ratio = 1) + 
  xlab("Interval between presentations") + 
  ylab("Accuracy")
p

```

# Alternative models

## Distance to proto - conv3

```{r}

df2_modeldisttoproto3 <- df %>% 
  group_by(subject_id,grp_order) %>% 
  do(divide_into_groups(.,"dist_to_proto_conv3","close_tgt","far_tgt"))
```

## Distance to proto - conv5

```{r}

df2_modeldisttoproto5 <- df %>% 
  group_by(subject_id,grp_order) %>% 
  do(divide_into_groups(.,"dist_to_proto_conv5","close_tgt","far_tgt"))
```

## Distance to targets - fc7


```{r}

df2_tgt_modeldist <- df2_tgt %>% 
  filter(layer == "dist_to_tgts") %>% 
  group_by(subject_id,grp_order) %>% 
  do(divide_into_groups(., "min_tgt_dist", "close_tgt", "far_tgt"))
```

## Memorability model

```{r}

df_perimage <- df %>% group_by(img_name,type) %>% summarize(m = mean(correct), sd = sd(correct)) %>% arrange(-m)
mem_imgnames <- read_csv(here("data/exp_DRM1/memorability/memorability_imgnames.txt"), col_names = F)
mem_values <- read_csv(here("data/exp_DRM1/memorability/memorability_all.txt"), col_names = F)

df_mem <- tibble(img_name = mem_imgnames$X1, mem_score = mem_values$X1)
dfm <- df %>% left_join(df_mem,by = "img_name") 


df2_modelmem <- dfm %>% 
  group_by(subject_id,grp_order) %>% 
  do(divide_into_groups(.,"mem_score", "low_memorable","high_memorable"))


```

### Ranking of images to category center

```{r}

c_cat_center_conv5 <- cor.test(~dist_to_cat_center_fc7+dist_to_cat_center_conv5, df, method = "sp")
c_cat_center_conv3 <- cor.test(~dist_to_cat_center_fc7+dist_to_cat_center_conv3, df, method = "sp")

c_fc7 <- cor.test(~ dist_to_cat_center_fc7+ dist_to_proto, df, method = "sp")
c_conv5 <- cor.test(~ dist_to_cat_center_conv5+ dist_to_proto_conv5, df, method = "sp")
c_conv3 <- cor.test(~ dist_to_cat_center_conv3+ dist_to_proto_conv3, df, method = "sp")

conv3_changed <- df2_modeldisttoproto3 %>% filter(type!="target") %>% xtabs(~type+model_type,.) %>% prop.table(1)
conv5_changed <- df2_modeldisttoproto5 %>% filter(type!="target") %>% xtabs(~type+model_type,.) %>% prop.table(1)

tgt_changes <- df2_tgt_modeldist %>% filter(type!="target") %>% xtabs(~type+model_type,.) %>% prop.table(1)
mem_changed <- df2_modelmem  %>% filter(type!="target") %>% xtabs(~type+model_type,.) %>% prop.table(1)
```

The first two models aimed to explore whether the high false alarm rate was driven by high level features (original fc7 model) or by low level features. We evaluated each image in convolutional layers conv3 and conv5, which represent the scenes’ lower visual features relative to their more semantic features in fc7 (models conv3 and conv5). Consequently, the proximity in higher levels does not need to be reflected in lower levels or vice versa. For example, the distances between scenes and their corresponding category centroids differ from fc7 (conv5: Spearman $\rho$ = `r c_cat_center_conv5$estimate %>% round(2)`; conv5: Spearman $\rho$ = `r c_cat_center_conv3$estimate %>% round(2)`). However, due to the selection of experimental stimuli (choosing targets closer to category centroids), the distances between visual prototype (the center of 15 targets) and category centroids are highly correlated. This correlation is preserved in lower layers (fc7: Spearman’s $\rho$ = `r c_fc7$estimate %>% round(2)`, conv5: Spearman’s $\rho$ = `r c_conv5$estimate %>% round(2)`, conv3: Spearman’s $\rho$ = `r c_conv3$estimate %>% round(2)`). When we again divided the distractors into close and far categories, the classification of distractors changed only in `r (100*conv5_changed[1,2]) %>% round(0)`% of cases for conv5 and `r (100*conv3_changed[1,2]) %>% round(0)`% of cases for conv3.

An alternative participant strategy for responding in the test phase would be to compare each presented scene with one of the targets. In such a case, the false alarm rate should be higher for scenes closer to one of the targets. Therefore, for each distractor, we computed the minimum distance to one of the targets (distance-to-targets model). However, as the targets were selected based on their proximity to the category centroid, this approach yielded a similar division of distractors into close and far (only `r (100*tgt_changes[1,2]) %>% round(0)`% of distractors were classified into the opposite category).

The final alternative model relies on estimated memorability (memorability model; Isola, Xiao, Torralba, & Oliva, 2011). We divided the scenes into lower and higher memorable scenes. Memorability is good candidate for predicting the task, because it has been demonstrated that memorable images show good perceptual organization (Goetschalckx, Moors, Vanmarcke, & Wagemans, 2018) and are quickly categorizable (Broers, Potter, & Nieuwenstein, 2018). Therefore, we evaluated the photographs using trained CNN MemNet, which can predict memorability resembling human performance (Khosla et al., 2015) . Although FIGRIM dataset contained ground-truth memorability scores for the subset of images, we decided to use estimated scores instead from MemNet instead as we needed memorability score for all images. Dividing scenes into groups with higher/lower memorability classified `r (100*mem_changed[1,1]) %>% round(0)`% close distractors as highly memorable, while for far distractors, it classified `r (100*mem_changed[2,1]) %>% round(0)`% of scenes as high memorable.

Evaluation of all the models showed similar results with weak explanatory power. For computation of the determination coefficient, we used formulas suggested by Nakagawa, Johnson, and Schielzeth (2017). This approach computed two versions of R2: conditional (model including both fixed and random effects) and marginal (including fixed effect only). Additionally, we also included a null model which has random factors only. As visualized in Table 1, the model distance to target showed the same results as the original model. Meanwhile, models relying on lower features conv5 and conv3 showed a decreasing FA rate with increasing depth. The memorability model showed the lowest fit.


```{r Table 1: False alarms for each of the alternative models }
print_table1()
```

```{r}
df_dist <- df %>% filter(type != "target") %>% group_by(type, img_name) %>% 
  summarize(FA = mean(1-correct), dist_to_cat_center_fc7 = mean(dist_to_cat_center_fc7), dist_to_proto_conv3 = mean(dist_to_proto_conv3), dist_to_proto_conv5 = mean(dist_to_proto_conv5)) %>% ungroup()
df2_tgt_corr <- df2_tgt %>% distinct() %>% filter(type != "target") %>% group_by(layer, type, img_name) %>% 
  summarize(FA = mean(1-correct), dist_to_tgt = mean(min_tgt_dist_no0)) %>% ungroup()

dist_proto <- df_dist %>% select(-type,-img_name) %>% 
  as.matrix() %>% 
  Hmisc::rcorr(type = "spearman")
dist_proto <- dist_proto$r %>% as_tibble() %>% filter(FA ==1)

dist_tgt <- (df2_tgt_corr %>% filter(layer == "dist_to_tgts") %>% 
  select(-type,-img_name,-layer) %>% 
  as.matrix() %>% 
  Hmisc::rcorr(type = "sp"))$r %>% as_tibble() %>% filter(FA == 1)

dist_mem <- dfm %>% filter(type != "target") %>% group_by(type, img_name) %>%
    summarize(FA = mean(1-correct), mem_score = mean(mem_score))  %>% 
  cor.test(~FA+mem_score,., method = "sp")
  
```

To extend our analysis beyond the qualitative division into close/far distractors, we also computed average FA rate for each distractor and correlated this FA rate with distances derived from each of the previously mentioned alternative models. All above-mentioned models showed a negative correlation between false alarms and individual metrics. In particular, for the original model, the correlation between FA and the distance to the category center was Spearman’s $\rho$ = `r dist_proto %>% pull(dist_to_cat_center_fc7) %>% round(2)`. For lower CNN layers, the correlations were smaller (conv3: $\rho$ = `r  dist_proto %>% pull(dist_to_proto_conv3) %>% round(2)`, conv5: $\rho$ = `r dist_proto %>% pull(dist_to_proto_conv5) %>% round(2)`). For the distance-to-target model, the correlation between minimum distance to target and FA was largest ($\rho$ = `r dist_tgt %>% pull(dist_to_tgt) %>% round(2)`). The memorability model showed the smallest correlation with FA ($\rho$ = `r dist_mem$estimate %>% round(2)`). These results are in line with those of previous models based on the division of distractors into two groups.

```{r}
cont_entropy <- read_csv(here("data/exp_DRM1/cats_entrophy.csv"), col_names = F) %>% rename(category = X1, cont_entropy = X2) %>% mutate(category = str_replace(category, "_", " "))
df_cont_entropy <- df %>% left_join(cont_entropy, by = "category") 


CE_close_dist <- df_cont_entropy %>% 
  filter(type == "close distractor") %>% 
  group_by(category) %>% 
  summarize(FA = mean(1-correct), cont_entropy = mean(cont_entropy)) %>% 
  cor.test(~FA+cont_entropy,., method = "sp")

CE_far_dist <- df_cont_entropy %>% 
  filter(type == "far distractor") %>% 
  group_by(category) %>% 
  summarize(FA = mean(1-correct), cont_entropy = mean(cont_entropy)) %>% 
  cor.test(~FA+cont_entropy,., method = "sp")


```

```{r}
df_hits <- df %>% 
    filter(type == "target") %>% 
  group_by(category) %>% 
  summarize(H = mean(correct))

df_fas <- df %>% 
    filter(type == "close distractor") %>% 
  group_by(category) %>% 
  summarize(FA = mean(1-correct))
df_hits %>% left_join(df_fas) %>% cor.test(~H+FA,., method = "sp")

df_fas_far <- df %>% 
    filter(type == "far distractor") %>% 
  group_by(category) %>% 
  summarize(FA = mean(1-correct))

df_hFA_close <- df_hits %>% left_join(df_fas)
df_hFA_far <- df_hits %>% left_join(df_fas_far)


c_HFA_close <- df_hFA_close %>% cor.test(~H+FA,.,method ="sp")
c_HFA_far <- df_hFA_far %>% cor.test(~H+FA,.,method ="sp")
```

Previous results showed that the explained variance of the presented models was small in comparison to the variance of subjects and categories. The differences in false alarm rates between categories are visualized in Figure 11. The variance in the FA rate was smaller for the far distractors, while the FA rate was larger for close distractors. To quantify category variability, we used context entropy as described in Bylinskii et al. (2015). This measure from the theory of information captures the variability of categories using context-dependent entropy. At the category level, this metric negatively correlated with the FA rate for close distractors (Spearman’s ρ = `r CE_close_dist$estimate %>% round(2)`), while it correlated positively with the FA rate for far distractors (Spearman’s ρ = `r CE_far_dist$estimate %>% round(2)`). A similar pattern was observed for correlation between recognition accuracy (for targets) and FA rate (close distractors: ρ = `r c_HFA_close$estimate %>% round(2)`, far distractors: ρ = `r c_HFA_far$estimate %>% round(2)`). In other words, in more homogenous categories, people are likely to confuse close distractors with targets (higher FA). However, it is easier for them to identify correctly far distractors as distractors (lower FA). In more variable categories, both effects are smaller: close distractors differ more from the targets, and far distractors are not so different from prototypical stimuli. 
